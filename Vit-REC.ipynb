{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e60b1648-d80b-4b6e-b3bc-5ba8a1be21fa",
   "metadata": {},
   "source": [
    "# VitRec (CUDA Edition) — Vision Transformer for Recommendation\n",
    "\n",
    "Datasets (He et al. 2017 split):\n",
    "- `data/ml-1m.train.rating` — implicit positives (user, item)\n",
    "- `data/ml-1m.test.rating` — held-out positive per user\n",
    "- `data/ml-1m.test.negative` — for each user: 1 positive + 99 negatives\n",
    "\n",
    "Evaluation: per-user **HR@K** and **NDCG@K** on those 100 candidates (no leakage).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a0fd5-92ee-48d6-b2ba-cefe9818dd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "#  Cell 1 — GPU & Environment Diagnostics\n",
    "# ====================================================\n",
    "import os, platform, torch\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"   # show real CUDA error lines\n",
    "\n",
    "print(\"Python:\", platform.python_version())\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"Built with CUDA:\", torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise SystemExit(\" CUDA not detected — please install a CUDA-enabled PyTorch build.\")\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "print(\"Using device:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# Quick CUDA sanity check\n",
    "try:\n",
    "    x = torch.zeros(1, device=DEVICE)\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"✅ CUDA sanity check passed.\")\n",
    "    print(\"cuDNN version:\", torch.backends.cudnn.version())\n",
    "    mem = torch.cuda.get_device_properties(DEVICE).total_memory / 1024**3\n",
    "    print(f\"Total GPU memory: {mem:.2f} GB\")\n",
    "except Exception as e:\n",
    "    raise SystemExit(\" CUDA failed to initialize:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372810b0-f501-43a9-b1db-f71bf05b827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#  Cell 2 — Imports, Configurations, and Random Seeds\n",
    "# ============================================================\n",
    "import os, os.path as osp, glob, time, random, math\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "# cuDNN tuning\n",
    "cudnn.benchmark = True\n",
    "cudnn.deterministic = False\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# ======================================\n",
    "#  Master configuration (safe defaults)\n",
    "# ======================================\n",
    "CFG = dict(\n",
    "    # Data\n",
    "    data_path     = \"data\",\n",
    "    data_set      = \"ml-1m\",\n",
    "    model_path    = \"model_ckpts\",\n",
    "\n",
    "    # Training\n",
    "    objective     = \"BPR\",        # or \"BCE\"\n",
    "    epochs        = 50,\n",
    "    batch_size    = 256,          # <=512 for 6 GB GPU\n",
    "    lr            = 3e-4,\n",
    "    weight_decay  = 1e-4,\n",
    "    warmup_epochs = 3,\n",
    "    num_ng        = 4,            # negatives per positive\n",
    "    top_k         = 10,\n",
    "    amp           = True,\n",
    "\n",
    "    # Model\n",
    "    embed_dim     = 32,\n",
    "    vit_depth     = 2,\n",
    "    num_heads     = 4,\n",
    "    patch_size    = 8,\n",
    "    dropout       = 0.1,\n",
    "\n",
    "    # Loader\n",
    "    num_workers   = 2,\n",
    "    pin_memory    = True,\n",
    "    seed          = SEED,\n",
    ")\n",
    "\n",
    "assert CFG[\"embed_dim\"] % CFG[\"num_heads\"]  == 0\n",
    "assert CFG[\"embed_dim\"] % CFG[\"patch_size\"] == 0\n",
    "\n",
    "origin    = os.getcwd()\n",
    "DATA_DIR  = osp.join(origin, CFG[\"data_path\"])\n",
    "DATA_FILE = osp.join(DATA_DIR, CFG[\"data_set\"])\n",
    "\n",
    "expected = [DATA_FILE + \".train.rating\", DATA_FILE + \".test.rating\", DATA_FILE + \".test.negative\"]\n",
    "print(\" Checking dataset files:\")\n",
    "for p in expected:\n",
    "    print(\"  -\", p, \"[OK]\" if osp.exists(p) else \"[MISSING]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3f2038-5f81-4cb5-b62d-671e239aed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "#  Cell 3 — Data Loading Utilities (fixed for ID gaps)\n",
    "# ====================================================\n",
    "def load_all(path_prefix: str):\n",
    "    \"\"\"Load train/test splits and reindex user/item IDs to 0-based contiguous range.\"\"\"\n",
    "    train_file = path_prefix + \".train.rating\"\n",
    "    test_file  = path_prefix + \".test.rating\"\n",
    "\n",
    "    # --- Load train ---\n",
    "    df = pd.read_csv(train_file, sep='\\t', names=['user', 'item', 'rating', 'timestamp'])\n",
    "    unique_users = sorted(df.user.unique())\n",
    "    unique_items = sorted(df.item.unique())\n",
    "\n",
    "    # Build mappings: original_id → new_id\n",
    "    user_map = {u: i for i, u in enumerate(unique_users)}\n",
    "    item_map = {i: j for j, i in enumerate(unique_items)}\n",
    "\n",
    "    # Remap to contiguous IDs\n",
    "    df['user'] = df['user'].map(user_map)\n",
    "    df['item'] = df['item'].map(item_map)\n",
    "\n",
    "    user_num = len(user_map)\n",
    "    item_num = len(item_map)\n",
    "    train_data = df[['user', 'item']].values.tolist()\n",
    "\n",
    "    # Build sparse train matrix\n",
    "    mat = sp.dok_matrix((user_num, item_num), dtype=np.float32)\n",
    "    for u, i in train_data:\n",
    "        mat[u, i] = 1.0\n",
    "\n",
    "    # --- Load test and remap ---\n",
    "    test_df = pd.read_csv(test_file, sep='\\t', names=['user', 'item', 'rating', 'timestamp'])\n",
    "    test_df = test_df[test_df.user.isin(user_map)]   # ensure overlap\n",
    "    test_df = test_df[test_df.item.isin(item_map)]\n",
    "    test_df['user'] = test_df['user'].map(user_map)\n",
    "    test_df['item'] = test_df['item'].map(item_map)\n",
    "    test_data = test_df[['user', 'item']].values.tolist()\n",
    "\n",
    "    print(f\"Reindexed users: {user_num}, items: {item_num}\")\n",
    "    return train_data, test_data, user_num, item_num, mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2789f29d-33ee-4da5-8aaa-0e9bb86b0c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "#  Cell 4 — BPR Dataset (fixed unpacking issue)\n",
    "# ====================================================\n",
    "class BPRDataset(Dataset):\n",
    "    \"\"\"Bayesian Personalized Ranking with negative sampling.\"\"\"\n",
    "    def __init__(self, train_data, item_num, train_mat, num_ng=4):\n",
    "        self.train_data = train_data\n",
    "        self.item_num = item_num\n",
    "        self.train_mat = train_mat\n",
    "        self.num_ng = num_ng\n",
    "        self.samples = self._ng_sample()\n",
    "\n",
    "    def _ng_sample(self):\n",
    "        samples = []\n",
    "        for u, i in self.train_data:\n",
    "            for _ in range(self.num_ng):\n",
    "                j = np.random.randint(self.item_num)\n",
    "                while (u, j) in self.train_mat:\n",
    "                    j = np.random.randint(self.item_num)\n",
    "                samples.append([u, i, j])\n",
    "        return samples\n",
    "\n",
    "    def ng_sample(self, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        self.samples = self._ng_sample()\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "         u, i, j = self.samples[idx]\n",
    "         return (\n",
    "           torch.tensor(u, dtype=torch.long),\n",
    "           torch.tensor(i, dtype=torch.long),\n",
    "           torch.tensor(j, dtype=torch.long),\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4035cb19-bed4-494a-8851-d56c21f86c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Cell 5 — ViT-based Collaborative Filtering Model (Paper Version)\n",
    "# ====================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleVisionTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Minimal Vision Transformer backbone for recommender use.\n",
    "    Each input is a 3×d×d \"interaction map\".\n",
    "    \"\"\"\n",
    "    def __init__(self, in_chans=3, embed_dim=64, patch_size=8, depth=2,\n",
    "                 num_heads=4, mlp_ratio=4.0, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Flatten patches (like ViT patch embedding)\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim,\n",
    "                              kernel_size=patch_size,\n",
    "                              stride=patch_size)\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.pos_embed = None  # optional positional embedding\n",
    "        self.pos_drop = nn.Dropout(dropout)\n",
    "\n",
    "        # Transformer encoder stack\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=int(embed_dim * mlp_ratio),\n",
    "            dropout=dropout,\n",
    "            activation=\"gelu\",\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=depth)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
    "\n",
    "    def forward(self, x):  # x: [B, 3, d, d]\n",
    "        B = x.size(0)\n",
    "        x = self.proj(x)                      # [B, embed_dim, H', W']\n",
    "        x = x.flatten(2).transpose(1, 2)      # [B, N, embed_dim]\n",
    "        cls = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls, x), dim=1)\n",
    "        x = self.pos_drop(x)\n",
    "        x = self.encoder(x)\n",
    "        x = self.norm(x)\n",
    "        return x[:, 0]                        # CLS token as global feature\n",
    "\n",
    "\n",
    "class ViTRecModel(nn.Module):\n",
    "    \"\"\"\n",
    "    ViT-based Collaborative Filtering model (outer product → ViT → score).\n",
    "    \"\"\"\n",
    "    def __init__(self, user_count, item_count, embed_dim=64,\n",
    "                 patch_size=8, depth=2, num_heads=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.user_count = user_count\n",
    "        self.item_count = item_count\n",
    "        self.embed_dim  = embed_dim\n",
    "        self.spatial_shape = (embed_dim, embed_dim)\n",
    "\n",
    "        # ----- ID Embeddings -----\n",
    "        self.user_emb = nn.Embedding(user_count, embed_dim)\n",
    "        self.item_emb = nn.Embedding(item_count, embed_dim)\n",
    "\n",
    "        # ----- ViT Backbone -----\n",
    "        self.vit = SimpleVisionTransformer(\n",
    "            in_chans=3,\n",
    "            embed_dim=embed_dim,\n",
    "            patch_size=patch_size,\n",
    "            depth=depth,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # ----- Prediction Head -----\n",
    "        self.fc1 = nn.Linear(embed_dim, embed_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.out = nn.Linear(embed_dim, 1)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        #  User and item embeddings\n",
    "        u = self.user_emb(user_ids)    # [B, d]\n",
    "        v = self.item_emb(item_ids)    # [B, d]\n",
    "\n",
    "        #  Outer product → interaction “image”\n",
    "        inter = torch.bmm(u.unsqueeze(2), v.unsqueeze(1))  # [B, d, d]\n",
    "        inter = inter.unsqueeze(1)                         # [B, 1, d, d]\n",
    "        img = inter.repeat(1, 3, 1, 1)                     # [B, 3, d, d]\n",
    "\n",
    "        # Vision Transformer backbone\n",
    "        feat = self.vit(img)                               # [B, d]\n",
    "        feat = self.dropout(torch.relu(feat))\n",
    "\n",
    "        # 4️Prediction head\n",
    "        x = self.fc1(feat)\n",
    "        x = self.out(x).squeeze(-1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7de49d-82da-45ef-99e3-7da9460ab8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Cell 6 — Evaluation Metrics (HR, NDCG)\n",
    "# ====================================================\n",
    "def hit(gt_item, pred_items):\n",
    "    return int(gt_item in pred_items)\n",
    "\n",
    "def ndcg(gt_item, pred_items):\n",
    "    if gt_item in pred_items:\n",
    "        index = pred_items.index(gt_item)\n",
    "        return np.reciprocal(np.log2(index + 2))\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5d0c4b-8adb-4f0a-b6e9-8f687eb1ab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "#  Cell 6.5 — TestUserDataset (robust version)\n",
    "# ====================================================\n",
    "class TestUserDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Robust loader for ML-1M test.negative file\n",
    "    Handles both '42\\t100 200 300...' and '(42,100)\\t...' formats.\n",
    "    \"\"\"\n",
    "    def __init__(self, path_prefix: str):\n",
    "        test_file = path_prefix + \".test.negative\"\n",
    "        self.users, self.items = [], []\n",
    "\n",
    "        with open(test_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue  # skip blank lines\n",
    "                \n",
    "                # Split on whitespace or tab\n",
    "                parts = line.replace('(', ' ').replace(')', ' ').replace(',', ' ').split()\n",
    "                if len(parts) < 2:\n",
    "                    continue  # skip malformed lines\n",
    "\n",
    "                try:\n",
    "                    user = int(parts[0])\n",
    "                except ValueError:\n",
    "                    # Try extracting the user from \"42:\" or \"userID\"\n",
    "                    cleaned = ''.join([c for c in parts[0] if c.isdigit()])\n",
    "                    if cleaned:\n",
    "                        user = int(cleaned)\n",
    "                    else:\n",
    "                        continue  # skip if still bad\n",
    "\n",
    "                # Convert rest to items\n",
    "                items = []\n",
    "                for token in parts[1:]:\n",
    "                    try:\n",
    "                        items.append(int(token))\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "\n",
    "                if items:\n",
    "                    self.users.append(user)\n",
    "                    self.items.append(items)\n",
    "\n",
    "        print(f\"Loaded {len(self.users)} users for testing.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user = torch.tensor(self.users[idx], dtype=torch.long)\n",
    "        items = torch.tensor(self.items[idx], dtype=torch.long)\n",
    "        return user, items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351e9898-f177-4542-86ad-08aa58218d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Cell 7 — DataLoader Setup\n",
    "# ====================================================\n",
    "train_data, test_data_flat, user_num, item_num, train_mat = load_all(DATA_FILE)\n",
    "print(f\"Users: {user_num}, Items: {item_num}, Train pairs: {len(train_data)}\")\n",
    "\n",
    "train_ds = BPRDataset(train_data, item_num, train_mat, num_ng=CFG['num_ng'])\n",
    "test_ds  = TestUserDataset(DATA_FILE)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=CFG['batch_size'],\n",
    "                          shuffle=True, num_workers=CFG['num_workers'],\n",
    "                          pin_memory=CFG['pin_memory'], drop_last=True)\n",
    "\n",
    "test_loader  = DataLoader(test_ds, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7507b79-d134-4ef5-8c15-56d00814d101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Cell 8 — Model, Optimizer, AMP Scaler & Scheduler Setup\n",
    "# ====================================================\n",
    "model = ViTRecModel(\n",
    "    user_num,\n",
    "    item_num,\n",
    "    embed_dim=CFG['embed_dim'],\n",
    "    patch_size=CFG['patch_size'],\n",
    "    depth=CFG['vit_depth'],\n",
    "    num_heads=CFG['num_heads'],\n",
    "    dropout=CFG['dropout']\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n",
    "scaler = GradScaler('cuda', enabled=CFG['amp'])\n",
    "\n",
    "# ----------------------------\n",
    "# Scheduler with cosine warmup\n",
    "# ----------------------------\n",
    "total_steps  = CFG['epochs'] * len(train_loader)\n",
    "warmup_steps = CFG['warmup_epochs'] * len(train_loader)\n",
    "\n",
    "def lr_lambda(step):\n",
    "    if step < warmup_steps: \n",
    "        return step / max(1, warmup_steps)\n",
    "    progress = (step - warmup_steps) / max(1, total_steps - warmup_steps)\n",
    "    return 0.5 * (1.0 + math.cos(math.pi * progress))\n",
    "\n",
    "scheduler = LambdaLR(optimizer, lr_lambda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84792184-bcf0-4885-a24d-e8c15a568ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "#  Cell 9 Training + Inline Evaluation (HR@K, NDCG@K)\n",
    "# ====================================================\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def evaluate(model, test_loader, top_k=10):\n",
    "    model.eval()\n",
    "    HRs, NDCGs = [], []\n",
    "    with torch.no_grad():\n",
    "        for user, items in test_loader:\n",
    "            user, items = user.to(DEVICE), items.to(DEVICE)\n",
    "            logits = model(user.repeat_interleave(items.size(1)), items)\n",
    "            _, topk = torch.topk(logits, top_k)\n",
    "            pred = items[0][topk.cpu().numpy()].tolist()\n",
    "            gt = items[0][0].item()\n",
    "            HRs.append(int(gt in pred))\n",
    "            if gt in pred:\n",
    "                index = pred.index(gt)\n",
    "                NDCGs.append(1 / np.log2(index + 2))\n",
    "            else:\n",
    "                NDCGs.append(0)\n",
    "    return np.mean(HRs), np.mean(NDCGs)\n",
    "\n",
    "\n",
    "for epoch in range(CFG['epochs']):\n",
    "    model.train()\n",
    "    train_loader.dataset.ng_sample(seed=CFG['seed'] + epoch)\n",
    "    total_loss = 0.0\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{CFG['epochs']}\", leave=True)\n",
    "    for batch in pbar:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        user, pos, neg = [x.to(DEVICE) for x in batch]\n",
    "        with autocast(device_type='cuda', enabled=CFG['amp']):\n",
    "            pos_logits = model(user, pos)\n",
    "            neg_logits = model(user, neg)\n",
    "            loss = -torch.log(torch.sigmoid(pos_logits - neg_logits) + 1e-8).mean()\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({\"Loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # ---- Evaluate each epoch ----\n",
    "    hr, ndcg = evaluate(model, test_loader, top_k=CFG['top_k'])\n",
    "    print(f\"\\n Epoch {epoch+1:02d}/{CFG['epochs']} \"\n",
    "          f\"| Avg Loss: {avg_loss:.4f} \"\n",
    "          f\"| HR@{CFG['top_k']}: {hr:.4f} \"\n",
    "          f\"| NDCG@{CFG['top_k']}: {ndcg:.4f}\\n\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea91eca-ff45-466c-a4a3-05c7ddb8db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "#  Cell 11 — Save Model Checkpoint\n",
    "# ====================================================\n",
    "os.makedirs(CFG['model_path'], exist_ok=True)\n",
    "ckpt_path = osp.join(CFG['model_path'], f\"vitrec_{CFG['data_set']}.pt\")\n",
    "torch.save(model.state_dict(), ckpt_path)\n",
    "print(\" Model saved to:\", ckpt_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fa8b12-0714-44c1-a385-45149641b298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
